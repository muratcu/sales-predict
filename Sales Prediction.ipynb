{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.express as px\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_excel(\"sales_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we will visualize sales for 1 item and 1 store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['Date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a table containing date and other variables related to date like \"day of week\" and \"week\" to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item='Item 1'\n",
    "store='Store A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales2=sales[sales['Item']==item]\n",
    "sales2=sales2[sales2['Store']==store]\n",
    "sales2['Date'] =  pd.to_datetime(sales2['Date'], dayfirst=True)\n",
    "def create_date_table(start, end):\n",
    "        df = pd.DataFrame({\"Date\": pd.date_range(start, end)})\n",
    "        df[\"Amount\"] = 0\n",
    "        df[\"Day\"] = df.Date.dt.day_name()\n",
    "        df[\"DayOfWeek\"] = df.Date.dt.weekday\n",
    "        df[\"Week\"] = df.Date.dt.weekofyear\n",
    "        df[\"Quarter\"] = df.Date.dt.quarter\n",
    "        df[\"Year\"] = df.Date.dt.year\n",
    "        df[\"Month\"] = df.Date.dt.month\n",
    "        df[\"DayOfMonth\"] = df.Date.dt.day\n",
    "        df[\"Year_half\"] = (df.Quarter + 1) // 2\n",
    "        return df\n",
    "    \n",
    "datedata=create_date_table('03.01.2020','30.08.2020')    \n",
    "dailysales=datedata.merge(sales2, on=\"Date\", how='left')\n",
    "dailysales2=dailysales[['Date','DayOfWeek','Week','Year','Month','DayOfMonth','Quantity']]\n",
    "dailysales3=dailysales2.groupby(['Date','DayOfWeek','Week','Year','Month','DayOfMonth'])['Quantity'].sum().reset_index(name ='Quantity')\n",
    "dailysales3.index = dailysales3['Date']    \n",
    "    \n",
    "start_date = pd.Timestamp('2020-05-01')\n",
    "end_date = pd.Timestamp('2020-06-01')\n",
    "dailysales3['Covid19'] = dailysales3['Date'].apply(lambda x: 1 if  (x > start_date) & (x <= end_date ) else 0 )\n",
    "    \n",
    "del dailysales3['Date']\n",
    "\n",
    "dailysales3['Quantity']=dailysales3['Quantity'].fillna(0)\n",
    "dailysales3['Weekend'] = dailysales3['DayOfWeek'].apply(lambda x: 1 if  (x == 5) | (x == 6 ) else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.lineplot(data=dailysales3,x=dailysales3.index,y=dailysales3['Quantity'],color=\"r\").set(title='Sales Over Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dailyreceipt=dailysales3.groupby(['DayOfWeek'])['Quantity'].mean().reset_index(name ='Quantity')\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.barplot(data=dailyreceipt,x=dailyreceipt['DayOfWeek'],y=dailyreceipt['Quantity']).set(title='Day Of Week Sales Distrubition')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that on thursday and friday sales increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.lineplot(data=dailysales3,x=dailysales3.DayOfMonth,y=dailysales3['Quantity'],color=\"r\").set(title='Day Of Month Sales Distrubition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(data=dailysales3,x=dailysales3.DayOfWeek,y=dailysales3['Quantity'],hue=dailysales3.Weekend).set(title='Compare Weekday and Weekend Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(data=dailysales3,x=dailysales3[\"DayOfMonth\"],y=dailysales3['Quantity']).set(title='Boxplot of sales over  Day Of Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the last week of month sales increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(data=dailysales3,x=dailysales3[\"DayOfWeek\"],y=dailysales3['Quantity'],hue=dailysales3[\"Covid19\"]).set(title='Visualize effect of Covid19 to sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "sns.lineplot(data=dailysales3,x=dailysales3['DayOfWeek'],y=dailysales3['Quantity'],hue=dailysales3.Covid19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that through Covid19 pick period sales has decreased but it keep the day of week trend the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLUSTER OF EACH ITEM ON EACH STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for ordering cluster numbers\n",
    "def order_cluster(cluster_field_name, target_field_name,df,ascending):\n",
    "    new_cluster_field_name = 'new_' + cluster_field_name\n",
    "    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n",
    "    df_new = df_new.sort_values(by=target_field_name,ascending=ascending).reset_index(drop=True)\n",
    "    df_new['index'] = df_new.index\n",
    "    df_final = pd.merge(df,df_new[[cluster_field_name,'index']], on=cluster_field_name)\n",
    "    df_final = df_final.drop([cluster_field_name],axis=1)\n",
    "    df_final = df_final.rename(columns={\"index\":cluster_field_name})\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sum_sales = sales.groupby(['Item','Store'])[\"Quantity\"].sum().reset_index().sort_values(['Item',\"Quantity\"], ascending=[True, False])\n",
    "#we will take into account items which has ben sold at least 8 stores \n",
    "count=sum_sales.groupby(['Item'])[\"Quantity\"].count().reset_index().sort_values(by=\"Quantity\",ascending=False)\n",
    "count=count[count[\"Quantity\"]>=8]\n",
    "itemlist=count['Item'].unique()\n",
    "columns = ['Item','Store',\"Quantity\"]\n",
    "df_ = pd.DataFrame(columns=columns)\n",
    "for i in itemlist:\n",
    "    sum_sales_item=sum_sales[sum_sales['Item']==i]\n",
    "    f_1 = sum_sales_item[\"Quantity\"].values\n",
    "    X=np.array(list(zip(f_1)))\n",
    "    distortions = []\n",
    "    K = range(1,10)\n",
    "    for k in K:\n",
    "        kmeanModel = KMeans(n_clusters=k)\n",
    "        kmeanModel.fit(X)\n",
    "        distortions.append(kmeanModel.inertia_)\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.plot(K, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title(i + ' The Elbow Method showing the optimal k')\n",
    "    plt.show()\n",
    "    kmeans=KMeans(n_clusters=4, init='k-means++').fit(X)\n",
    "    labels=kmeans.predict(X)\n",
    "    centroids=kmeans.cluster_centers_\n",
    "    sum_sales_item['Cluster'] = kmeans.predict(X)\n",
    "    #merge two dataframes\n",
    "    sum_sales_item = order_cluster('Cluster',\"Quantity\",sum_sales_item,False)\n",
    "    sum_sales_item['Cluster'].replace(0,'A',inplace=True)\n",
    "    sum_sales_item['Cluster'].replace(1,'B',inplace=True)\n",
    "    sum_sales_item['Cluster'].replace(2,'C',inplace=True)\n",
    "    sum_sales_item['Cluster'].replace(3,'D',inplace=True)\n",
    "    fig = px.bar(sum_sales_item, x='Store', y=\"Quantity\",\n",
    "              color='Cluster',title=i + \" Sales Graph\",\n",
    "              height=500)\n",
    "    fig.show()\n",
    "    df_=df_.append(sum_sales_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALES PREDICTION WITH XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items =sales['Item'].unique()\n",
    "stores=sales['Store'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "appended_data = []\n",
    "for k in items:\n",
    "    for i in stores:\n",
    "        sales2=sales[sales['Item']==k]\n",
    "        sales2=sales2[sales2['Store']==i]\n",
    "        sales2['Date'] =  pd.to_datetime(sales2['Date'], dayfirst=True)\n",
    "        def create_date_table(start, end):\n",
    "            df = pd.DataFrame({\"Date\": pd.date_range(start, end)})\n",
    "            df[\"Amount\"] = 0\n",
    "            df[\"Day\"] = df.Date.dt.day_name()\n",
    "            df[\"DayOfWeek\"] = df.Date.dt.weekday\n",
    "            df[\"Week\"] = df.Date.dt.weekofyear\n",
    "            df[\"Quarter\"] = df.Date.dt.quarter\n",
    "            df[\"Year\"] = df.Date.dt.year\n",
    "            df[\"Month\"] = df.Date.dt.month\n",
    "            df[\"DayOfMonth\"] = df.Date.dt.day\n",
    "            df[\"Year_half\"] = (df.Quarter + 1) // 2\n",
    "            return df\n",
    "    \n",
    "        datedata=create_date_table('03.01.2020','31.08.2020')    \n",
    "        dailysales=datedata.merge(sales2, on=\"Date\", how='left')\n",
    "        dailysales2=dailysales[['Date','DayOfWeek','Week','Year','Month','DayOfMonth','Quantity']]\n",
    "        dailysales3=dailysales2.groupby(['Date','DayOfWeek','Week','Year','Month','DayOfMonth'])['Quantity'].sum().reset_index(name ='Quantity')\n",
    "        dailysales3.index = dailysales3['Date']    \n",
    "    \n",
    "        start_date = pd.Timestamp('2020-05-01')\n",
    "        end_date = pd.Timestamp('2020-06-01')\n",
    "        dailysales3['Covid19'] = dailysales3['Date'].apply(lambda x: 1 if  (x > start_date) & (x <= end_date ) else 0 )\n",
    "    \n",
    "        del dailysales3['Date']\n",
    "\n",
    "        dailysales3['Quantity']=dailysales3['Quantity'].fillna(0)\n",
    "        dailysales3['Weekend'] = dailysales3['DayOfWeek'].apply(lambda x: 1 if  (x == 5) | (x == 6 ) else 0 )\n",
    "\n",
    "        plt.figure(figsize=(10,3))\n",
    "        dailysales3.plot(subplots=True)\n",
    "    \n",
    "        data=dailysales3.copy()\n",
    "        fig = px.line(data, x=data.index, y=\"Quantity\", title=' Before outliers smoothing'+ i )\n",
    "        fig.show()\n",
    "    \n",
    "        from scipy import stats\n",
    "        data['z_score']=stats.zscore(data['Quantity'])\n",
    "        fig = px.histogram(data, x=\"z_score\",nbins=10)\n",
    "        fig.show()\n",
    "    \n",
    "        data['Quantity_Es']=data['Quantity']\n",
    "        data['Quantity_Es'][data.z_score > 3] = data['Quantity'].ewm(alpha=0.2).mean()\n",
    "        data['Quantity_Es'][data.z_score < -2] = data['Quantity'].ewm(alpha=0.2).mean()\n",
    "        fig = px.line(data, x=data.index, y=\"Quantity_Es\", title=' After outliers smoothing'+ i )\n",
    "        fig.show()\n",
    "    \n",
    "        data=data.drop(['Quantity', 'z_score'], axis=1)\n",
    "        data_df=data.copy()\n",
    "        data_df['item_month_mean'] = data_df.groupby(['Month'])['Quantity_Es'].transform('mean')       \n",
    "        data_df['itemweekday_mean'] = data_df.groupby(['DayOfWeek'])['Quantity_Es'].transform('mean')\n",
    "        data_df['Previous'] = data_df.groupby('DayOfWeek')['Quantity_Es'].shift()\n",
    "        data_df['rolling_mean_7_days']=data_df['Quantity_Es'].rolling(7).apply(np.nanmean)\n",
    "        data_df.rolling_mean_7_days=data_df.rolling_mean_7_days.shift(1)\n",
    "        data_df['previous_day']=data_df['Quantity_Es'].shift(1)\n",
    "        data_df_2=data_df.dropna()\n",
    "    \n",
    "        regressor_xgboost=xgb.XGBRegressor(objective='reg:squarederror',eval_metric =\"mae\")\n",
    "        \n",
    "        x=data_df_2[data_df_2.index <= \"2020-08-30\"]\n",
    "        test = data_df_2[data_df_2.index > \"2020-08-30\"]\n",
    "        test = test[test.index <= \"2020-08-31\"]\n",
    "\n",
    "        y=x['Quantity_Es']\n",
    "    \n",
    "        x.drop(['Quantity_Es'],axis=1,inplace=True)\n",
    "        test.drop(['Quantity_Es'],axis=1,inplace=True)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1) # 70% training and 30% test\n",
    "        \n",
    "        #parameters = {'min_child_weight': [1,2,3],\n",
    "               #'max_depth':  [2,3,4],\n",
    "               #'colsample_bytree':  [0.1,0.3,0.5],\n",
    "              #'n_estimators':  [500,800],\n",
    "              #'alpha': [3,5,8]\n",
    "                #}\n",
    "        \n",
    "        parameters = {'min_child_weight': [1,2],\n",
    "               'max_depth':  [2,3],\n",
    "               'colsample_bytree':  [0.3,0.5],\n",
    "              'n_estimators':  [500,800],\n",
    "              'alpha': [3,5]\n",
    "                }\n",
    "            \n",
    "            \n",
    "        grid_xgboost = GridSearchCV(estimator=regressor_xgboost,param_grid=parameters) \n",
    "        grid_xgboost.fit(X_train,y_train)\n",
    "    \n",
    "        print( 'best score: {0:.4f}'.format(grid_xgboost.best_score_))\n",
    "        print( 'best parameters: {}'.format(grid_xgboost.best_params_))\n",
    "    \n",
    "        colsample_bytree = grid_xgboost.best_params_['colsample_bytree']\n",
    "        n_estimators = grid_xgboost.best_params_['n_estimators']\n",
    "        max_depth = grid_xgboost.best_params_['max_depth']\n",
    "        min_child_weight = grid_xgboost.best_params_['min_child_weight']\n",
    "        alpha = grid_xgboost.best_params_['alpha']\n",
    "    \n",
    "        xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = colsample_bytree ,\n",
    "                max_depth = max_depth, alpha = alpha, n_estimators = n_estimators, min_child_weight=min_child_weight)\n",
    "    \n",
    "        xg_reg.fit(X_train,y_train)\n",
    "        y_test_pred = xg_reg.predict(X_test)\n",
    "        print('xgBoost result train data')\n",
    "        print(mean_absolute_error(y_test, y_test_pred))\n",
    "        print(mean_squared_error(y_test, y_test_pred))\n",
    "        print(r2_score(y_test, y_test_pred))\n",
    "    \n",
    "        plt.figure(figsize=(16,6))\n",
    "        plt.plot(y_test.values,label=\"Actual data\")\n",
    "        plt.plot(y_test_pred,label=\"predicted values\")\n",
    "        plt.legend(loc=\"best\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        import matplotlib.pyplot as plt\n",
    "        xgb.plot_importance(xg_reg,importance_type='gain', height=0.5,ax=ax)\n",
    "        plt.show()\n",
    "        \n",
    "        #we then fit the whole dataset to predict next day purchase    \n",
    "        xg_reg.fit(x,y)\n",
    "    \n",
    "        preds_test = xg_reg.predict(test)\n",
    "        \n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        df['Sales_Predict'] = preds_test       \n",
    "        df['Item'] = k\n",
    "        df['Store'] = i\n",
    "        \n",
    "        \n",
    "        appended_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDF = pd.concat(appended_data, ignore_index=True)\n",
    "masterDF['Sales_Predict'][masterDF['Sales_Predict'] < 0] = 0\n",
    "masterDF_fill=masterDF .fillna(0)\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data_percent = []\n",
    "for k in items:\n",
    "    percent=masterDF_fill[masterDF_fill['Item']==k]\n",
    "    percent['percent']=percent['Sales_Predict']/percent['Sales_Predict'].sum()*100\n",
    "    appended_data_percent.append(percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sales predict\n",
    "masterDF_last = pd.concat(appended_data_percent, ignore_index=True)\n",
    "masterDF_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare Cluster of stores with sales predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for item 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDF_last_item_1=masterDF_last[masterDF_last['Item']=='Item 1']\n",
    "daily_sales_mean_item_1=masterDF_last_item_1.groupby(['Store'])['Sales_Predict'].mean().reset_index()\n",
    "df_item_1=df_[df_['Item']=='Item 1']\n",
    "lastDF_item_1=df_item_1.merge(daily_sales_mean_item_1, on=\"Store\", how='left')\n",
    "lastDF_item_1_last=lastDF_item_1.dropna()\n",
    "lastDF_item_1_last.groupby(['Cluster'])['Sales_Predict'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For item 1 the predicted values are in consistency with cluster of stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for item 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDF_last_item_2=masterDF_last[masterDF_last['Item']=='Item 2']\n",
    "daily_sales_mean_item_2=masterDF_last_item_2.groupby(['Store'])['Sales_Predict'].mean().reset_index()\n",
    "df_item_2=df_[df_['Item']=='Item 2']\n",
    "lastDF_item_2=df_item_2.merge(daily_sales_mean_item_2, on=\"Store\", how='left')\n",
    "lastDF_item_2_last=lastDF_item_2.dropna()\n",
    "lastDF_item_2_last.groupby(['Cluster'])['Sales_Predict'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For item 2 cluster C stores prediction is higher than cluster B stores. But we should keep in mind we predict the day monday. 31 August. So we will visualize sales of item 2 based on day of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales2=sales[sales['Item']=='Item 2']\n",
    "sales2['Date'] =  pd.to_datetime(sales2['Date'], dayfirst=True)\n",
    "def create_date_table(start, end):\n",
    "        df = pd.DataFrame({\"Date\": pd.date_range(start, end)})\n",
    "        df[\"Amount\"] = 0\n",
    "        df[\"Day\"] = df.Date.dt.day_name()\n",
    "        df[\"DayOfWeek\"] = df.Date.dt.weekday\n",
    "        df[\"Week\"] = df.Date.dt.weekofyear\n",
    "        df[\"Quarter\"] = df.Date.dt.quarter\n",
    "        df[\"Year\"] = df.Date.dt.year\n",
    "        df[\"Month\"] = df.Date.dt.month\n",
    "        df[\"DayOfMonth\"] = df.Date.dt.day\n",
    "        df[\"Year_half\"] = (df.Quarter + 1) // 2\n",
    "        return df\n",
    "    \n",
    "datedata=create_date_table('03.01.2020','30.08.2020')    \n",
    "dailysales=datedata.merge(sales2, on=\"Date\", how='left')\n",
    "dailysales2=dailysales[['Date','DayOfWeek','Week','Year','Month','DayOfMonth','Store','Quantity']]\n",
    "dailysales3=dailysales2.groupby(['Date','DayOfWeek','Week','Year','Month','DayOfMonth','Store'])['Quantity'].sum().reset_index(name ='Quantity')\n",
    "dailysales3.index = dailysales3['Date']    \n",
    "    \n",
    "start_date = pd.Timestamp('2020-05-01')\n",
    "end_date = pd.Timestamp('2020-06-01')\n",
    "dailysales3['Covid19'] = dailysales3['Date'].apply(lambda x: 1 if  (x > start_date) & (x <= end_date ) else 0 )\n",
    "    \n",
    "del dailysales3['Date']\n",
    "\n",
    "dailysales3['Quantity']=dailysales3['Quantity'].fillna(0)\n",
    "dailysales3['Weekend'] = dailysales3['DayOfWeek'].apply(lambda x: 1 if  (x == 5) | (x == 6 ) else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_2_cluster=df_[df_['Item']=='Item 2']\n",
    "df_item_2_cluster=df_item_2_cluster[['Store','Cluster']]\n",
    "dailysales3_merge=dailysales3.merge(df_item_2_cluster, on=\"Store\", how='left')\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.boxplot(data=dailysales3_merge,x=dailysales3_merge['DayOfWeek'],y=dailysales3_merge['Quantity'],hue=dailysales3_merge.Cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though on monday we see the median of Cluster B is higher than Cluster C , Cluster C has outliers higher than Cluster B, so on some Mondays Cluster C value might be higher than Cluster B value. We can say that below predict is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastDF_item_2_last.groupby(['Cluster'])['Sales_Predict'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
